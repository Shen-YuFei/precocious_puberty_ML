{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 性早熟预测模型\n",
    "\n",
    "**基线数据 + 动态特征结合**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量（必须在导入sklearn之前）\n",
    "import os\n",
    "\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import roc_curve\n",
    "import xgboost as xgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "import tabm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 定义MissForest插补器工厂函数\n",
    "def create_missforest_imputer(random_state=825):\n",
    "    \"\"\"创建MissForest插补器（IterativeImputer + RandomForest）\"\"\"\n",
    "    return IterativeImputer(\n",
    "        estimator=RandomForestRegressor(\n",
    "            n_estimators=10,\n",
    "            max_depth=10,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        ),\n",
    "        max_iter=10,\n",
    "        random_state=random_state,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"使用MissForest方法进行缺失值填补\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置路径和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "os.makedirs(\"../output/models\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 825\n",
    "np.random.seed(RANDOM_SEED)\n",
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = pd.read_csv(\"../input/性早熟数据激发试验正常组_new.csv\")\n",
    "disease_data = pd.read_csv(\"../input/激发试验确诊性早熟组数据_new.csv\")\n",
    "\n",
    "normal_data[\"group\"] = \"N\"\n",
    "disease_data[\"group\"] = \"Y\"\n",
    "\n",
    "print(f\"正常组: {normal_data.shape[0]} 行, 早熟组: {disease_data.shape[0]} 行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据类型处理和合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([normal_data, disease_data], axis=0, ignore_index=True)\n",
    "data[\"group\"] = data[\"group\"].astype(\"category\")\n",
    "print(f\"合并后数据: {data.shape[0]} 行 x {data.shape[1]} 列\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 查看数据基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"数据基本信息:\")\n",
    "print(f\"数据维度: {data.shape}\")\n",
    "print(f\"分组统计:\")\n",
    "print(data[\"group\"].value_counts())\n",
    "print(f\"数据类型:\")\n",
    "print(data.dtypes.value_counts())\n",
    "print(f\"缺失值统计:\")\n",
    "missing_count = data.isnull().sum().sum()\n",
    "print(f\"总缺失值数量: {missing_count}\")\n",
    "if missing_count > 0:\n",
    "    missing_by_col = data.isnull().sum()\n",
    "    missing_by_col = missing_by_col[missing_by_col > 0].sort_values(ascending=False)\n",
    "    print(\"各列缺失值:\")\n",
    "    print(missing_by_col.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(\n",
    "    data, test_size=0.3, stratify=data[\"group\"], random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"训练集: {train_data.shape[0]} 行, 验证集: {validation_data.shape[0]} 行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\"group\", \"患者编号\", \"Unnamed: 0\"]\n",
    "feature_cols = [col for col in train_data.columns if col not in exclude_cols]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[\"group\"].copy()\n",
    "X_validation = validation_data[feature_cols].copy()\n",
    "y_validation = validation_data[\"group\"].copy()\n",
    "\n",
    "y_train_binary = (y_train == \"Y\").astype(int)\n",
    "y_validation_binary = (y_validation == \"Y\").astype(int)\n",
    "\n",
    "print(f\"使用 {len(feature_cols)} 个特征\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 特征概览和缺失值分析/补缺（MissForest方法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 8. 特征概览 =====\n",
    "print(f\"特征列表 ({len(feature_cols)}个特征):\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n训练集: {X_train.shape[0]}样本, 验证集: {X_validation.shape[0]}样本\")\n",
    "print(f\"训练集正负样本: {y_train_binary.value_counts().to_dict()}\")\n",
    "print(f\"验证集正负样本: {y_validation_binary.value_counts().to_dict()}\")\n",
    "\n",
    "# ===== 缺失值分析 =====\n",
    "missing_train = X_train.isnull().sum()\n",
    "missing_pct = (missing_train / len(X_train) * 100).round(2)\n",
    "missing_info = (\n",
    "    pd.DataFrame({\"缺失数量\": missing_train, \"缺失率(%)\": missing_pct})\n",
    "    .query(\"缺失数量 > 0\")\n",
    "    .sort_values(\"缺失率(%)\", ascending=False)\n",
    ")\n",
    "\n",
    "if not missing_info.empty:\n",
    "    print(f\"\\n缺失值分析 (Top 10):\")\n",
    "    print(missing_info.head(10).to_string())\n",
    "\n",
    "# ===== 定义分类特征和数值特征 =====\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"缺失值填补（分类特征+数值特征分别处理）\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 分类特征及其有效取值范围\n",
    "categorical_info = {\n",
    "    \"Tanner分期\": (1, 5),  # 1-5\n",
    "    \"乳晕色素沉着\": (0, 2),  # 0, 1, 2\n",
    "    \"乳核\": (0, 1),  # 0, 1\n",
    "    \"有无阴毛\": (0, 1),  # 0, 1\n",
    "    \"有无腋毛\": (0, 1),  # 0, 1\n",
    "}\n",
    "\n",
    "categorical_cols = [c for c in categorical_info.keys() if c in feature_cols]\n",
    "numerical_cols = [c for c in feature_cols if c not in categorical_cols]\n",
    "\n",
    "print(f\"分类特征 ({len(categorical_cols)}个): {categorical_cols}\")\n",
    "print(f\"数值特征 ({len(numerical_cols)}个)\")\n",
    "\n",
    "# ===== 分类特征：使用 IterativeImputer + RandomForestClassifier =====\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cat_imputer = IterativeImputer(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        max_depth=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_SEED,\n",
    "    ),\n",
    "    max_iter=10,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "if categorical_cols:\n",
    "    print(\"使用 IterativeImputer + RandomForestClassifier 填补分类特征...\")\n",
    "    X_train_cat = cat_imputer.fit_transform(X_train[categorical_cols])\n",
    "    X_validation_cat = cat_imputer.transform(X_validation[categorical_cols])\n",
    "\n",
    "    # 裁剪到有效范围\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        min_val, max_val = categorical_info[col]\n",
    "        X_train_cat[:, i] = X_train_cat[:, i].clip(min_val, max_val)\n",
    "        X_validation_cat[:, i] = X_validation_cat[:, i].clip(min_val, max_val)\n",
    "\n",
    "    print(f\"分类特征填补完成\")\n",
    "\n",
    "# ===== 数值特征：使用MissForest方法 =====\n",
    "imputer = create_missforest_imputer(RANDOM_SEED)\n",
    "print(\"使用MissForest方法填补数值特征...\")\n",
    "\n",
    "X_train_num = imputer.fit_transform(X_train[numerical_cols])\n",
    "X_validation_num = imputer.transform(X_validation[numerical_cols])\n",
    "\n",
    "# ===== 合并分类和数值特征 =====\n",
    "if categorical_cols:\n",
    "    X_train_arr = np.hstack([X_train_cat, X_train_num])\n",
    "    X_validation_arr = np.hstack([X_validation_cat, X_validation_num])\n",
    "    feature_cols_processed = categorical_cols + numerical_cols\n",
    "else:\n",
    "    X_train_arr = X_train_num\n",
    "    X_validation_arr = X_validation_num\n",
    "    feature_cols_processed = numerical_cols\n",
    "\n",
    "# 转换为DataFrame保持列名\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    X_train_arr, columns=feature_cols_processed, index=X_train.index\n",
    ")\n",
    "X_validation_imputed = pd.DataFrame(\n",
    "    X_validation_arr, columns=feature_cols_processed, index=X_validation.index\n",
    ")\n",
    "\n",
    "# 标准化（用于KNN/SVM/NNET等模型）\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_validation_scaled = scaler.transform(X_validation_imputed)\n",
    "\n",
    "print(f\"\\n填补完成！\")\n",
    "print(f\"  处理后特征数: {X_train_imputed.shape[1]}\")\n",
    "print(f\"  缺失值检查: {X_train_imputed.isnull().sum().sum()} (应为0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 模型训练\n",
    "\n",
    "## 10. 设置交叉验证策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_strategy = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"验证策略: 5折交叉验证 x 3次重复 = {cv_strategy.get_n_splits()}轮\")\n",
    "print(f\"训练集: {len(X_train)}样本, 正负比={y_train_binary.value_counts().to_dict()}\")\n",
    "print(\n",
    "    f\"验证集: {len(X_validation)}样本, 正负比={y_validation_binary.value_counts().to_dict()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 训练模型1: GBM (梯度提升机)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    l2_regularization=0.1,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "gbm_model.fit(X_train, y_train_binary)\n",
    "\n",
    "y_pred_gbm = gbm_model.predict(X_validation)\n",
    "y_pred_proba_gbm = gbm_model.predict_proba(X_validation)[:, 1]\n",
    "auc_gbm = roc_auc_score(y_validation_binary, y_pred_proba_gbm)\n",
    "f1_gbm = f1_score(y_validation_binary, y_pred_gbm)\n",
    "\n",
    "joblib.dump(gbm_model, \"../output/models/gbm_model.pkl\")\n",
    "print(f\"GBM AUC: {auc_gbm:.4f}, F1: {f1_gbm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 训练模型2: KNN (K近邻)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN使用标准化数据\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=N_JOBS)\n",
    "knn_model.fit(X_train_scaled, y_train_binary)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_validation_scaled)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_validation_scaled)[:, 1]\n",
    "auc_knn = roc_auc_score(y_validation_binary, y_pred_proba_knn)\n",
    "f1_knn = f1_score(y_validation_binary, y_pred_knn)\n",
    "\n",
    "joblib.dump(\n",
    "    {\"model\": knn_model, \"imputer\": imputer, \"scaler\": scaler},\n",
    "    \"../output/models/knn_model.pkl\",\n",
    ")\n",
    "print(f\"KNN AUC: {auc_knn:.4f}, F1: {f1_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 训练模型3: Naive Bayes (朴素贝叶斯)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB使用填补后数据（无需标准化）\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_imputed, y_train_binary)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_validation_imputed)\n",
    "y_pred_proba_nb = nb_model.predict_proba(X_validation_imputed)[:, 1]\n",
    "auc_nb = roc_auc_score(y_validation_binary, y_pred_proba_nb)\n",
    "f1_nb = f1_score(y_validation_binary, y_pred_nb)\n",
    "\n",
    "joblib.dump({\"model\": nb_model, \"imputer\": imputer}, \"../output/models/nb_model.pkl\")\n",
    "print(f\"NB AUC: {auc_nb:.4f}, F1: {f1_nb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 训练模型4: XGBoost (极限梯度提升)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.013,\n",
    "    random_state=RANDOM_SEED,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=N_JOBS,\n",
    ")\n",
    "xgb_model.fit(X_train, y_train_binary)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_validation)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_validation)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_validation_binary, y_pred_proba_xgb)\n",
    "f1_xgb = f1_score(y_validation_binary, y_pred_xgb)\n",
    "\n",
    "joblib.dump(xgb_model, \"../output/models/xgb_model.pkl\")\n",
    "print(f\"XGB AUC: {auc_xgb:.4f}, F1: {f1_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 训练模型5: Random Forest (随机森林)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500, random_state=RANDOM_SEED, n_jobs=N_JOBS\n",
    ")\n",
    "rf_model.fit(X_train, y_train_binary)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_validation)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_validation)[:, 1]\n",
    "auc_rf = roc_auc_score(y_validation_binary, y_pred_proba_rf)\n",
    "f1_rf = f1_score(y_validation_binary, y_pred_rf)\n",
    "\n",
    "joblib.dump(rf_model, \"../output/models/rf_model.pkl\")\n",
    "print(f\"RF AUC: {auc_rf:.4f}, F1: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 训练模型6: RPART (决策树)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPART使用填补后数据\n",
    "rpart_model = DecisionTreeClassifier(\n",
    "    max_depth=5, min_samples_split=50, min_samples_leaf=20, random_state=RANDOM_SEED\n",
    ")\n",
    "rpart_model.fit(X_train_imputed, y_train_binary)\n",
    "\n",
    "y_pred_rpart = rpart_model.predict(X_validation_imputed)\n",
    "y_pred_proba_rpart = rpart_model.predict_proba(X_validation_imputed)[:, 1]\n",
    "auc_rpart = roc_auc_score(y_validation_binary, y_pred_proba_rpart)\n",
    "f1_rpart = f1_score(y_validation_binary, y_pred_rpart)\n",
    "\n",
    "joblib.dump(\n",
    "    {\"model\": rpart_model, \"imputer\": imputer}, \"../output/models/rpart_model.pkl\"\n",
    ")\n",
    "print(f\"RPART AUC: {auc_rpart:.4f}, F1: {f1_rpart:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. 训练模型7: GLM (逻辑回归)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM使用填补后数据\n",
    "glm_model = LogisticRegression(max_iter=1000, random_state=RANDOM_SEED, n_jobs=N_JOBS)\n",
    "glm_model.fit(X_train_imputed, y_train_binary)\n",
    "\n",
    "y_pred_glm = glm_model.predict(X_validation_imputed)\n",
    "y_pred_proba_glm = glm_model.predict_proba(X_validation_imputed)[:, 1]\n",
    "auc_glm = roc_auc_score(y_validation_binary, y_pred_proba_glm)\n",
    "f1_glm = f1_score(y_validation_binary, y_pred_glm)\n",
    "\n",
    "joblib.dump({\"model\": glm_model, \"imputer\": imputer}, \"../output/models/glm_model.pkl\")\n",
    "print(f\"GLM AUC: {auc_glm:.4f}, F1: {f1_glm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. 训练模型8: SVM (支持向量机)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM使用标准化数据\n",
    "svm_model = SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_SEED)\n",
    "svm_model.fit(X_train_scaled, y_train_binary)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_validation_scaled)\n",
    "y_pred_proba_svm = svm_model.predict_proba(X_validation_scaled)[:, 1]\n",
    "auc_svm = roc_auc_score(y_validation_binary, y_pred_proba_svm)\n",
    "f1_svm = f1_score(y_validation_binary, y_pred_svm)\n",
    "\n",
    "joblib.dump(\n",
    "    {\"model\": svm_model, \"imputer\": imputer, \"scaler\": scaler},\n",
    "    \"../output/models/svm_model.pkl\",\n",
    ")\n",
    "print(f\"SVM AUC: {auc_svm:.4f}, F1: {f1_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. 训练模型9: NNET (神经网络)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNET使用标准化数据\n",
    "nnet_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    max_iter=500,\n",
    "    random_state=RANDOM_SEED,\n",
    "    early_stopping=True,\n",
    ")\n",
    "nnet_model.fit(X_train_scaled, y_train_binary)\n",
    "\n",
    "y_pred_nnet = nnet_model.predict(X_validation_scaled)\n",
    "y_pred_proba_nnet = nnet_model.predict_proba(X_validation_scaled)[:, 1]\n",
    "auc_nnet = roc_auc_score(y_validation_binary, y_pred_proba_nnet)\n",
    "f1_nnet = f1_score(y_validation_binary, y_pred_nnet)\n",
    "\n",
    "joblib.dump(\n",
    "    {\"model\": nnet_model, \"imputer\": imputer, \"scaler\": scaler},\n",
    "    \"../output/models/nnet_model.pkl\",\n",
    ")\n",
    "print(f\"NNET AUC: {auc_nnet:.4f}, F1: {f1_nnet:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. 导入模型10: TabM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入最佳TabM模型\n",
    "print(\"=\" * 70)\n",
    "print(\"导入最佳TabM模型\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import rtdl_num_embeddings\n",
    "\n",
    "# 加载预处理器和配置\n",
    "tabm_data = joblib.load(\"../output/models/tabm_preprocessors.pkl\")\n",
    "best_model_name = tabm_data.get(\"best_model_name\", \"basic\")\n",
    "saved_metrics = tabm_data.get(\"metrics\", {})\n",
    "\n",
    "print(f\"最佳模型: TabM-{best_model_name}\")\n",
    "if saved_metrics:\n",
    "    print(\n",
    "        f\"保存时性能: F1={saved_metrics.get('f1', 'N/A'):.4f}, AUC={saved_metrics.get('auc', 'N/A'):.4f}\"\n",
    "    )\n",
    "\n",
    "# 数据预处理\n",
    "X_train_processed = X_train_imputed.values\n",
    "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32).cuda()\n",
    "y_train_tensor = torch.tensor(y_train_binary.values, dtype=torch.long).cuda()\n",
    "X_val_tensor = torch.tensor(X_validation_imputed.values, dtype=torch.float32).cuda()\n",
    "\n",
    "print(f\"训练集: {X_train_tensor.shape}, 验证集: {X_val_tensor.shape}\")\n",
    "\n",
    "# 根据最佳模型类型创建对应架构\n",
    "model_kwargs = {\n",
    "    \"n_num_features\": X_train_tensor.shape[1],\n",
    "    \"cat_cardinalities\": [],\n",
    "    \"d_out\": 2,\n",
    "}\n",
    "\n",
    "# 默认嵌入参数\n",
    "n_bins = 48\n",
    "d_embedding = 16\n",
    "use_periodic = False\n",
    "\n",
    "# 如果是HPO模型，尝试加载HPO配置\n",
    "if best_model_name == \"hpo\":\n",
    "    hpo_config_path = \"../output/tabm_enhanced/models/tabm_hpo_config.pkl\"\n",
    "    if os.path.exists(hpo_config_path):\n",
    "        hpo_data = joblib.load(hpo_config_path)\n",
    "        best_params = hpo_data[\"best_params\"]\n",
    "        n_bins = best_params[\"n_bins\"]\n",
    "        d_embedding = best_params[\"d_embedding\"]\n",
    "        model_kwargs[\"n_blocks\"] = best_params[\"n_blocks\"]\n",
    "        model_kwargs[\"d_block\"] = best_params[\"d_block\"]\n",
    "        model_kwargs[\"dropout\"] = best_params[\"dropout\"]\n",
    "        print(\n",
    "            f\"HPO参数: n_blocks={best_params['n_blocks']}, d_block={best_params['d_block']}, dropout={best_params['dropout']}\"\n",
    "        )\n",
    "elif best_model_name == \"mini\":\n",
    "    model_kwargs[\"arch_type\"] = \"tabm-mini\"\n",
    "elif best_model_name == \"periodic\":\n",
    "    use_periodic = True\n",
    "\n",
    "# 创建嵌入层\n",
    "if use_periodic:\n",
    "    num_embeddings = rtdl_num_embeddings.PeriodicEmbeddings(\n",
    "        n_features=X_train_tensor.shape[1],\n",
    "        d_embedding=d_embedding,\n",
    "        lite=False,\n",
    "    )\n",
    "else:\n",
    "    num_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "        rtdl_num_embeddings.compute_bins(X_train_tensor, n_bins=n_bins),\n",
    "        d_embedding=d_embedding,\n",
    "        activation=False,\n",
    "        version=\"B\",\n",
    "    )\n",
    "\n",
    "model_kwargs[\"num_embeddings\"] = num_embeddings\n",
    "\n",
    "# 创建模型\n",
    "tabm_model = tabm.TabM.make(**model_kwargs).cuda()\n",
    "\n",
    "# 加载权重\n",
    "tabm_model.load_state_dict(\n",
    "    torch.load(\"../output/models/tabm_best.pt\", map_location=\"cuda\", weights_only=True)\n",
    ")\n",
    "tabm_model.eval()\n",
    "\n",
    "print(f\"模型参数量: {sum(p.numel() for p in tabm_model.parameters()):,}\")\n",
    "\n",
    "# 验证集评估\n",
    "with torch.no_grad():\n",
    "    val_logits = tabm_model(X_val_tensor, None)\n",
    "    y_pred_proba_tabm = (\n",
    "        torch.softmax(val_logits, dim=-1).mean(dim=1)[:, 1].cpu().numpy()\n",
    "    )\n",
    "    y_pred_tabm = (y_pred_proba_tabm >= 0.5).astype(int)\n",
    "\n",
    "auc_tabm = roc_auc_score(y_validation_binary, y_pred_proba_tabm)\n",
    "f1_tabm = f1_score(y_validation_binary, y_pred_tabm)\n",
    "\n",
    "print(f\"\\nTabM验证集性能: F1={f1_tabm:.4f}, AUC={auc_tabm:.4f}\")\n",
    "print(f\"模型来源: ../output/models/tabm_best.pt\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. 导入模型11: TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"加载Post-hoc集成TabPFN模型\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 加载模型文件\n",
    "auto_model_path = \"../output/tabpfn_enhanced/models/tabpfn_auto.pkl\"\n",
    "\n",
    "# 加载模型和预处理器\n",
    "auto_data = joblib.load(auto_model_path)\n",
    "tabpfn_model = auto_data[\"model\"]\n",
    "\n",
    "print(f\"已加载Post-hoc集成TabPFN模型\")\n",
    "print(f\"模型路径: {auto_model_path}\")\n",
    "print(f\"模型类型: {type(tabpfn_model).__name__}\")\n",
    "\n",
    "# 使用已填补的数据（本notebook已在前面完成填补）\n",
    "X_train_tabpfn = X_train_imputed.values\n",
    "X_validation_tabpfn = X_validation_imputed.values\n",
    "\n",
    "print(f\"训练集: {X_train_tabpfn.shape}, 验证集: {X_validation_tabpfn.shape}\")\n",
    "\n",
    "# 验证集预测\n",
    "print(f\"\\n在验证集上进行预测...\")\n",
    "y_pred_tabpfn = tabpfn_model.predict(X_validation_tabpfn)\n",
    "y_pred_proba_tabpfn = tabpfn_model.predict_proba(X_validation_tabpfn)[:, 1]\n",
    "\n",
    "# 计算性能指标\n",
    "auc_tabpfn = roc_auc_score(y_validation_binary, y_pred_proba_tabpfn)\n",
    "f1_tabpfn = f1_score(y_validation_binary, y_pred_tabpfn)\n",
    "\n",
    "print(f\"\\nPost-hoc集成TabPFN性能指标:\")\n",
    "print(f\"  AUC: {auc_tabpfn:.4f}\")\n",
    "print(f\"  F1:  {f1_tabpfn:.4f}\")\n",
    "\n",
    "# 保存到与其他模型一致的位置\n",
    "joblib.dump(\n",
    "    {\"model\": tabpfn_model},\n",
    "    \"../output/models/tabpfn_model.pkl\",\n",
    ")\n",
    "print(f\"\\n模型已复制到: ../output/models/tabpfn_model.pkl\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型性能汇总\n",
    "models_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"模型\": [\n",
    "            \"GBM\",\n",
    "            \"KNN\",\n",
    "            \"NB\",\n",
    "            \"XGB\",\n",
    "            \"RF\",\n",
    "            \"RPART\",\n",
    "            \"GLM\",\n",
    "            \"SVM\",\n",
    "            \"NNET\",\n",
    "            \"TabPFN-HPO\",\n",
    "            \"TabM\",\n",
    "        ],\n",
    "        \"AUC\": [\n",
    "            auc_gbm,\n",
    "            auc_knn,\n",
    "            auc_nb,\n",
    "            auc_xgb,\n",
    "            auc_rf,\n",
    "            auc_rpart,\n",
    "            auc_glm,\n",
    "            auc_svm,\n",
    "            auc_nnet,\n",
    "            auc_tabpfn,\n",
    "            auc_tabm,\n",
    "        ],\n",
    "        \"F1\": [\n",
    "            f1_gbm,\n",
    "            f1_knn,\n",
    "            f1_nb,\n",
    "            f1_xgb,\n",
    "            f1_rf,\n",
    "            f1_rpart,\n",
    "            f1_glm,\n",
    "            f1_svm,\n",
    "            f1_nnet,\n",
    "            f1_tabpfn,\n",
    "            f1_tabm,\n",
    "        ],\n",
    "    }\n",
    ").sort_values(\"AUC\", ascending=False)\n",
    "\n",
    "best_model_name = models_summary.iloc[0][\"模型\"]\n",
    "best_model_auc = models_summary.iloc[0][\"AUC\"]\n",
    "best_model_f1 = models_summary.iloc[0][\"F1\"]\n",
    "\n",
    "print(f\"模型性能 ({len(models_summary)}个模型):\")\n",
    "print(models_summary.to_string(index=False))\n",
    "print(\n",
    "    f\"\\n最佳模型: {best_model_name} (AUC = {best_model_auc:.4f}, F1 = {best_model_f1:.4f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# ROC曲线对比\n",
    "models_info = [\n",
    "    (\"GBM\", y_pred_proba_gbm, auc_gbm),\n",
    "    (\"KNN\", y_pred_proba_knn, auc_knn),\n",
    "    (\"NB\", y_pred_proba_nb, auc_nb),\n",
    "    (\"XGB\", y_pred_proba_xgb, auc_xgb),\n",
    "    (\"RF\", y_pred_proba_rf, auc_rf),\n",
    "    (\"RPART\", y_pred_proba_rpart, auc_rpart),\n",
    "    (\"GLM\", y_pred_proba_glm, auc_glm),\n",
    "    (\"SVM\", y_pred_proba_svm, auc_svm),\n",
    "    (\"NNET\", y_pred_proba_nnet, auc_nnet),\n",
    "    (\"TabPFN-HPO\", y_pred_proba_tabpfn, auc_tabpfn),\n",
    "    (\"TabM\", y_pred_proba_tabm, auc_tabm),\n",
    "]\n",
    "\n",
    "for model_name, y_proba, auc_score in models_info:\n",
    "    fpr, tpr, _ = roc_curve(y_validation_binary, y_proba)\n",
    "    linewidth = 3 if model_name in [\"TabPFN-HPO\", \"TabM\"] else 2\n",
    "    plt.plot(\n",
    "        fpr, tpr, label=f\"{model_name} (AUC = {auc_score:.4f})\", linewidth=linewidth\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", linewidth=1, label=\"随机猜测\")\n",
    "plt.xlabel(\"假阳性率 (1-特异度)\", fontsize=12)\n",
    "plt.ylabel(\"真阳性率 (灵敏度)\", fontsize=12)\n",
    "plt.title(\"11个模型的ROC曲线对比（含TabPFN-HPO和TabM）\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../output/ROC曲线对比_11模型.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"../output/ROC曲线对比_11模型.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC曲线已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存预测结果和性能指标\n",
    "predictions_df = pd.DataFrame(\n",
    "    {\n",
    "        \"真实标签\": y_validation_binary,\n",
    "        \"GBM_预测\": y_pred_gbm,\n",
    "        \"GBM_概率\": y_pred_proba_gbm,\n",
    "        \"KNN_预测\": y_pred_knn,\n",
    "        \"KNN_概率\": y_pred_proba_knn,\n",
    "        \"NB_预测\": y_pred_nb,\n",
    "        \"NB_概率\": y_pred_proba_nb,\n",
    "        \"XGB_预测\": y_pred_xgb,\n",
    "        \"XGB_概率\": y_pred_proba_xgb,\n",
    "        \"RF_预测\": y_pred_rf,\n",
    "        \"RF_概率\": y_pred_proba_rf,\n",
    "        \"RPART_预测\": y_pred_rpart,\n",
    "        \"RPART_概率\": y_pred_proba_rpart,\n",
    "        \"GLM_预测\": y_pred_glm,\n",
    "        \"GLM_概率\": y_pred_proba_glm,\n",
    "        \"SVM_预测\": y_pred_svm,\n",
    "        \"SVM_概率\": y_pred_proba_svm,\n",
    "        \"NNET_预测\": y_pred_nnet,\n",
    "        \"NNET_概率\": y_pred_proba_nnet,\n",
    "        \"TabPFN-HPO_预测\": y_pred_tabpfn,\n",
    "        \"TabPFN-HPO_概率\": y_pred_proba_tabpfn,\n",
    "        \"TabM_预测\": y_pred_tabm,\n",
    "        \"TabM_概率\": y_pred_proba_tabm,\n",
    "    }\n",
    ")\n",
    "\n",
    "predictions_df.to_csv(\n",
    "    \"../output/验证集预测结果_11模型.csv\", index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(f\"预测结果已保存，验证集共 {len(predictions_df)} 样本，包含11个模型的预测\")\n",
    "\n",
    "# 保存模型性能汇总\n",
    "models_summary.to_csv(\n",
    "    \"../output/模型性能汇总_AUC_F1.csv\", index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(f\"模型性能汇总已保存 (包含AUC和F1指标)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PPML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

