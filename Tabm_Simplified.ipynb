{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabM精简版：性早熟预测模型\n",
    "\n",
    "**使用精简特征集（22个特征）进行模型训练**\n",
    "\n",
    "精简特征基于医生临床经验筛选：\n",
    "- LH/FSH 相关：基础LH、基础FSH、LH/FSH比值\n",
    "- 骨龄相关：骨龄、骨龄与实际年龄比值、生物年龄和骨龄之间的差异\n",
    "- 子宫卵巢径线/体积：子宫长宽厚体积、左右卵巢长宽厚体积、卵巢平均值\n",
    "\n",
    "本笔记本流程与 Tabm_Enhanced.ipynb 一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tabm\n",
    "import rtdl_num_embeddings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "print(f\"TabM版本: {tabm.__version__ if hasattr(tabm, '__version__') else 'N/A'}\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU设备: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"所有库导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置路径和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "os.makedirs(\"./output/tabm_simplified\", exist_ok=True)\n",
    "os.makedirs(\"./output/tabm_simplified/models\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 825\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"随机种子设置: {RANDOM_SEED}\")\n",
    "print(f\"计算设备: {DEVICE}\")\n",
    "print(f\"输出目录: ./output/tabm_simplified/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 读取精简特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = pd.read_csv(\"./input/性早熟数据激发试验正常组_simplified.csv\")\n",
    "disease_data = pd.read_csv(\"./input/激发试验确诊性早熟组数据_simplified.csv\")\n",
    "\n",
    "normal_data[\"group\"] = \"N\"\n",
    "disease_data[\"group\"] = \"Y\"\n",
    "\n",
    "print(f\"正常组: {normal_data.shape[0]} 行, {normal_data.shape[1]} 列\")\n",
    "print(f\"早熟组: {disease_data.shape[0]} 行, {disease_data.shape[1]} 列\")\n",
    "print(f\"\\n精简特征列表:\")\n",
    "for col in normal_data.columns:\n",
    "    if col not in [\"group\", \"患者编号\"]:\n",
    "        print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据合并与划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([normal_data, disease_data], axis=0, ignore_index=True)\n",
    "data[\"group\"] = data[\"group\"].astype(\"category\")\n",
    "print(f\"合并后数据: {data.shape[0]} 行 x {data.shape[1]} 列\")\n",
    "print(f\"分组统计:\\n{data['group'].value_counts()}\")\n",
    "\n",
    "train_data, validation_data = train_test_split(\n",
    "    data, test_size=0.3, stratify=data[\"group\"], random_state=RANDOM_SEED\n",
    ")\n",
    "print(f\"\\n训练集: {train_data.shape[0]} 行, 验证集: {validation_data.shape[0]} 行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 特征工程与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\"group\", \"患者编号\", \"Unnamed: 0\"]\n",
    "feature_cols = [col for col in train_data.columns if col not in exclude_cols]\n",
    "\n",
    "X_train = train_data[feature_cols].copy()\n",
    "y_train = train_data[\"group\"].copy()\n",
    "X_validation = validation_data[feature_cols].copy()\n",
    "y_validation = validation_data[\"group\"].copy()\n",
    "\n",
    "y_train_binary = (y_train == \"Y\").astype(int)\n",
    "y_validation_binary = (y_validation == \"Y\").astype(int)\n",
    "\n",
    "print(f\"使用 {len(feature_cols)} 个精简特征\")\n",
    "print(f\"训练集正负样本: {y_train_binary.value_counts().to_dict()}\")\n",
    "print(f\"验证集正负样本: {y_validation_binary.value_counts().to_dict()}\")\n",
    "\n",
    "# 缺失值填充\n",
    "imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=10, max_depth=10, n_jobs=-1, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    max_iter=10,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=0,\n",
    ")\n",
    "print(\"\\n使用MissForest方法填补缺失值...\")\n",
    "X_train_num = imputer.fit_transform(X_train)\n",
    "X_validation_num = imputer.transform(X_validation)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_processed = scaler.fit_transform(X_train_num)\n",
    "X_validation_processed = scaler.transform(X_validation_num)\n",
    "print(\"数值特征已标准化\")\n",
    "\n",
    "feature_cols_processed = feature_cols\n",
    "print(f\"\\n预处理完成！特征数: {X_train_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 数据转换为PyTorch张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32).to(DEVICE)\n",
    "y_train_tensor = torch.tensor(y_train_binary.values, dtype=torch.long).to(DEVICE)\n",
    "X_val_tensor = torch.tensor(X_validation_processed, dtype=torch.float32).to(DEVICE)\n",
    "y_val_tensor = torch.tensor(y_validation_binary.values, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "print(f\"训练集张量: {X_train_tensor.shape}\")\n",
    "print(f\"验证集张量: {X_val_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 定义训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tabm_model(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_epochs=500,\n",
    "    batch_size=256,\n",
    "    lr=2e-3,\n",
    "    weight_decay=3e-4,\n",
    "    patience=32,\n",
    "    gradient_clipping_norm=1.0,\n",
    "    share_training_batches=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    amp_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "    amp_enabled = torch.cuda.is_available()\n",
    "\n",
    "    best_f1, best_auc, best_epoch, best_state = 0, 0, 0, None\n",
    "    remaining_patience = patience\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        if share_training_batches:\n",
    "            batches = torch.randperm(len(X_train), device=DEVICE).split(batch_size)\n",
    "        else:\n",
    "            batches = (\n",
    "                torch.rand((len(X_train), model.backbone.k), device=DEVICE)\n",
    "                .argsort(dim=0)\n",
    "                .split(batch_size, dim=0)\n",
    "            )\n",
    "\n",
    "        for batch_idx in batches:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(\n",
    "                device_type=\"cuda\", enabled=amp_enabled, dtype=amp_dtype\n",
    "            ):\n",
    "                logits = model(X_train[batch_idx], None)\n",
    "                y_pred = logits.flatten(0, 1)\n",
    "                if share_training_batches:\n",
    "                    y_true = y_train[batch_idx].repeat_interleave(model.backbone.k)\n",
    "                else:\n",
    "                    y_true = y_train[batch_idx].flatten(0, 1)\n",
    "                loss = nn.functional.cross_entropy(y_pred, y_true)\n",
    "            loss.backward()\n",
    "            if gradient_clipping_norm:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(), gradient_clipping_norm\n",
    "                )\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = model(X_val, None)\n",
    "            val_proba = (\n",
    "                torch.softmax(val_logits, dim=-1).mean(dim=1)[:, 1].cpu().numpy()\n",
    "            )\n",
    "            val_pred = (val_proba >= 0.5).astype(int)\n",
    "            y_val_np = y_val.cpu().numpy()\n",
    "            auc = roc_auc_score(y_val_np, val_proba)\n",
    "            f1 = f1_score(y_val_np, val_pred)\n",
    "\n",
    "        improved = f1 > best_f1\n",
    "        if verbose and (epoch % 50 == 0 or improved):\n",
    "            print(\n",
    "                f\"Epoch {epoch:3d}: Loss={total_loss/len(batches):.4f}, F1={f1:.4f}, AUC={auc:.4f}{' *' if improved else ''}\"\n",
    "            )\n",
    "        if improved:\n",
    "            best_f1, best_auc, best_epoch = f1, auc, epoch\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            remaining_patience = patience\n",
    "        else:\n",
    "            remaining_patience -= 1\n",
    "        if remaining_patience < 0:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    return {\"best_f1\": best_f1, \"best_auc\": best_auc, \"best_epoch\": best_epoch}\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X, None)\n",
    "        proba = torch.softmax(logits, dim=-1).mean(dim=1)[:, 1].cpu().numpy()\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        y_np = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n",
    "        return {\n",
    "            \"auc\": roc_auc_score(y_np, proba),\n",
    "            \"f1\": f1_score(y_np, pred),\n",
    "            \"accuracy\": accuracy_score(y_np, pred),\n",
    "            \"y_pred\": pred,\n",
    "            \"y_proba\": proba,\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"训练和评估函数定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 模型1：基础TabM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"训练基础TabM模型（精简特征）\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "num_embeddings_basic = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "    rtdl_num_embeddings.compute_bins(X_train_tensor, n_bins=48),\n",
    "    d_embedding=16,\n",
    "    activation=False,\n",
    "    version=\"B\",\n",
    ")\n",
    "tabm_basic = tabm.TabM.make(\n",
    "    n_num_features=X_train_tensor.shape[1],\n",
    "    cat_cardinalities=[],\n",
    "    d_out=2,\n",
    "    num_embeddings=num_embeddings_basic,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"模型参数量: {sum(p.numel() for p in tabm_basic.parameters()):,}\")\n",
    "print(f\"特征数: {X_train_tensor.shape[1]}\")\n",
    "\n",
    "result_basic = train_tabm_model(\n",
    "    tabm_basic,\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    X_val_tensor,\n",
    "    y_val_tensor,\n",
    "    n_epochs=500,\n",
    "    patience=500,\n",
    ")\n",
    "metrics_basic = evaluate_model(tabm_basic, X_val_tensor, y_val_tensor)\n",
    "\n",
    "print(\n",
    "    f\"\\n基础TabM性能: AUC={metrics_basic['auc']:.4f}, F1={metrics_basic['f1']:.4f}, ACC={metrics_basic['accuracy']:.4f}\"\n",
    ")\n",
    "torch.save(tabm_basic.state_dict(), \"./output/tabm_simplified/models/tabm_basic.pt\")\n",
    "joblib.dump(\n",
    "    {\"imputer\": imputer, \"scaler\": scaler},\n",
    "    \"./output/tabm_simplified/models/tabm_basic_preprocessors.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 模型2：TabM-Mini架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"训练TabM-Mini架构（精简特征）\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "num_embeddings_mini = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "    rtdl_num_embeddings.compute_bins(X_train_tensor, n_bins=48),\n",
    "    d_embedding=16,\n",
    "    activation=False,\n",
    "    version=\"B\",\n",
    ")\n",
    "tabm_mini = tabm.TabM.make(\n",
    "    n_num_features=X_train_tensor.shape[1],\n",
    "    cat_cardinalities=[],\n",
    "    d_out=2,\n",
    "    num_embeddings=num_embeddings_mini,\n",
    "    arch_type=\"tabm-mini\",\n",
    ").to(DEVICE)\n",
    "\n",
    "result_mini = train_tabm_model(\n",
    "    tabm_mini,\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    X_val_tensor,\n",
    "    y_val_tensor,\n",
    "    n_epochs=500,\n",
    "    patience=500,\n",
    ")\n",
    "metrics_mini = evaluate_model(tabm_mini, X_val_tensor, y_val_tensor)\n",
    "\n",
    "print(\n",
    "    f\"\\nTabM-Mini性能: AUC={metrics_mini['auc']:.4f}, F1={metrics_mini['f1']:.4f}, ACC={metrics_mini['accuracy']:.4f}\"\n",
    ")\n",
    "torch.save(tabm_mini.state_dict(), \"./output/tabm_simplified/models/tabm_mini.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 模型3：独立批次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"训练TabM（独立批次策略）\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "num_embeddings_indep = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "    rtdl_num_embeddings.compute_bins(X_train_tensor, n_bins=48),\n",
    "    d_embedding=16,\n",
    "    activation=False,\n",
    "    version=\"B\",\n",
    ")\n",
    "tabm_indep = tabm.TabM.make(\n",
    "    n_num_features=X_train_tensor.shape[1],\n",
    "    cat_cardinalities=[],\n",
    "    d_out=2,\n",
    "    num_embeddings=num_embeddings_indep,\n",
    ").to(DEVICE)\n",
    "\n",
    "result_indep = train_tabm_model(\n",
    "    tabm_indep,\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    X_val_tensor,\n",
    "    y_val_tensor,\n",
    "    n_epochs=500,\n",
    "    patience=500,\n",
    "    share_training_batches=False,\n",
    ")\n",
    "metrics_indep = evaluate_model(tabm_indep, X_val_tensor, y_val_tensor)\n",
    "\n",
    "print(\n",
    "    f\"\\nTabM独立批次性能: AUC={metrics_indep['auc']:.4f}, F1={metrics_indep['f1']:.4f}, ACC={metrics_indep['accuracy']:.4f}\"\n",
    ")\n",
    "torch.save(tabm_indep.state_dict(), \"./output/tabm_simplified/models/tabm_indep.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 模型4：PeriodicEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"训练TabM（PeriodicEmbeddings）\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "num_embeddings_periodic = rtdl_num_embeddings.PeriodicEmbeddings(\n",
    "    n_features=X_train_tensor.shape[1],\n",
    "    d_embedding=16,\n",
    "    lite=False,\n",
    ")\n",
    "tabm_periodic = tabm.TabM.make(\n",
    "    n_num_features=X_train_tensor.shape[1],\n",
    "    cat_cardinalities=[],\n",
    "    d_out=2,\n",
    "    num_embeddings=num_embeddings_periodic,\n",
    ").to(DEVICE)\n",
    "\n",
    "result_periodic = train_tabm_model(\n",
    "    tabm_periodic,\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    X_val_tensor,\n",
    "    y_val_tensor,\n",
    "    n_epochs=500,\n",
    "    patience=500,\n",
    ")\n",
    "metrics_periodic = evaluate_model(tabm_periodic, X_val_tensor, y_val_tensor)\n",
    "\n",
    "print(\n",
    "    f\"\\nTabM-Periodic性能: AUC={metrics_periodic['auc']:.4f}, F1={metrics_periodic['f1']:.4f}, ACC={metrics_periodic['accuracy']:.4f}\"\n",
    ")\n",
    "torch.save(\n",
    "    tabm_periodic.state_dict(), \"./output/tabm_simplified/models/tabm_periodic.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 模型5：超参数优化（Optuna HPO）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TabM超参数优化（Optuna）\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_hpo_model_state = None\n",
    "best_hpo_f1 = 0.0\n",
    "best_hpo_config = None\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    global best_hpo_model_state, best_hpo_f1, best_hpo_config\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 1, 4)\n",
    "    d_block = trial.suggest_int(\"d_block\", 64, 512, step=64)\n",
    "    n_bins = trial.suggest_int(\"n_bins\", 16, 96, step=16)\n",
    "    d_embedding = trial.suggest_int(\"d_embedding\", 8, 32, step=4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3, step=0.05)\n",
    "    try:\n",
    "        num_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "            rtdl_num_embeddings.compute_bins(X_train_tensor, n_bins=n_bins),\n",
    "            d_embedding=d_embedding,\n",
    "            activation=False,\n",
    "            version=\"B\",\n",
    "        )\n",
    "        model = tabm.TabM.make(\n",
    "            n_num_features=X_train_tensor.shape[1],\n",
    "            cat_cardinalities=[],\n",
    "            d_out=2,\n",
    "            num_embeddings=num_embeddings,\n",
    "            n_blocks=n_blocks,\n",
    "            d_block=d_block,\n",
    "            dropout=dropout,\n",
    "        ).to(DEVICE)\n",
    "        result = train_tabm_model(\n",
    "            model,\n",
    "            X_train_tensor,\n",
    "            y_train_tensor,\n",
    "            X_val_tensor,\n",
    "            y_val_tensor,\n",
    "            n_epochs=200,\n",
    "            patience=50,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            verbose=False,\n",
    "        )\n",
    "        f1 = result[\"best_f1\"]\n",
    "        if f1 > best_hpo_f1:\n",
    "            best_hpo_f1 = f1\n",
    "            best_hpo_model_state = deepcopy(model.state_dict())\n",
    "            best_hpo_config = {\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"d_block\": d_block,\n",
    "                \"n_bins\": n_bins,\n",
    "                \"d_embedding\": d_embedding,\n",
    "                \"dropout\": dropout,\n",
    "            }\n",
    "        return f1\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"tabm_simplified_hpo\")\n",
    "study.optimize(objective, n_trials=1000, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n最佳参数: {study.best_params}\")\n",
    "print(f\"最佳F1: {study.best_value:.4f}\")\n",
    "\n",
    "torch.save(best_hpo_model_state, \"./output/tabm_simplified/models/tabm_hpo.pt\")\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"best_params\": study.best_params,\n",
    "        \"best_config\": best_hpo_config,\n",
    "        \"imputer\": imputer,\n",
    "        \"scaler\": scaler,\n",
    "    },\n",
    "    \"./output/tabm_simplified/models/tabm_hpo_config.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 评估HPO最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings_hpo = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "    rtdl_num_embeddings.compute_bins(X_train_tensor, n_bins=best_hpo_config[\"n_bins\"]),\n",
    "    d_embedding=best_hpo_config[\"d_embedding\"],\n",
    "    activation=False,\n",
    "    version=\"B\",\n",
    ")\n",
    "tabm_hpo = tabm.TabM.make(\n",
    "    n_num_features=X_train_tensor.shape[1],\n",
    "    cat_cardinalities=[],\n",
    "    d_out=2,\n",
    "    num_embeddings=num_embeddings_hpo,\n",
    "    n_blocks=best_hpo_config[\"n_blocks\"],\n",
    "    d_block=best_hpo_config[\"d_block\"],\n",
    "    dropout=best_hpo_config[\"dropout\"],\n",
    ").to(DEVICE)\n",
    "tabm_hpo.load_state_dict(best_hpo_model_state)\n",
    "metrics_hpo = evaluate_model(tabm_hpo, X_val_tensor, y_val_tensor)\n",
    "print(\n",
    "    f\"HPO优化TabM性能: AUC={metrics_hpo['auc']:.4f}, F1={metrics_hpo['f1']:.4f}, ACC={metrics_hpo['accuracy']:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 性能对比与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"模型\": [\n",
    "            \"基础TabM\",\n",
    "            \"TabM-Mini\",\n",
    "            \"TabM独立批次\",\n",
    "            \"TabM-Periodic\",\n",
    "            \"HPO优化TabM\",\n",
    "        ],\n",
    "        \"AUC\": [\n",
    "            metrics_basic[\"auc\"],\n",
    "            metrics_mini[\"auc\"],\n",
    "            metrics_indep[\"auc\"],\n",
    "            metrics_periodic[\"auc\"],\n",
    "            metrics_hpo[\"auc\"],\n",
    "        ],\n",
    "        \"F1\": [\n",
    "            metrics_basic[\"f1\"],\n",
    "            metrics_mini[\"f1\"],\n",
    "            metrics_indep[\"f1\"],\n",
    "            metrics_periodic[\"f1\"],\n",
    "            metrics_hpo[\"f1\"],\n",
    "        ],\n",
    "        \"ACC\": [\n",
    "            metrics_basic[\"accuracy\"],\n",
    "            metrics_mini[\"accuracy\"],\n",
    "            metrics_indep[\"accuracy\"],\n",
    "            metrics_periodic[\"accuracy\"],\n",
    "            metrics_hpo[\"accuracy\"],\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(\"TabM精简特征模型性能对比\")\n",
    "print(results.to_string(index=False))\n",
    "results.to_csv(\"./output/tabm_simplified/性能对比.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "models_data = [\n",
    "    (\"基础TabM\", metrics_basic),\n",
    "    (\"TabM-Mini\", metrics_mini),\n",
    "    (\"TabM独立批次\", metrics_indep),\n",
    "    (\"TabM-Periodic\", metrics_periodic),\n",
    "    (\"HPO优化TabM\", metrics_hpo),\n",
    "]\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "for (name, m), color in zip(models_data, colors):\n",
    "    fpr, tpr, _ = roc_curve(y_validation_binary, m[\"y_proba\"])\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={m['auc']:.4f})\", color=color, linewidth=2)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", linewidth=1)\n",
    "ax.set_xlabel(\"假阳性率\", fontsize=12)\n",
    "ax.set_ylabel(\"真阳性率\", fontsize=12)\n",
    "ax.set_title(\"TabM精简特征模型ROC曲线对比\", fontsize=14)\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./output/tabm_simplified/ROC曲线对比.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, y_proba):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return {\n",
    "        \"AUC\": roc_auc_score(y_true, y_proba),\n",
    "        \"F1\": f1_score(y_true, y_pred),\n",
    "        \"ACC\": accuracy_score(y_true, y_pred),\n",
    "        \"敏感性\": sens,\n",
    "        \"特异性\": spec,\n",
    "        \"TP\": tp,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "    }\n",
    "\n",
    "\n",
    "y_val_np = y_validation_binary.values\n",
    "detailed = []\n",
    "for name, m in models_data:\n",
    "    d = calc_metrics(y_val_np, m[\"y_pred\"], m[\"y_proba\"])\n",
    "    d[\"模型\"] = name\n",
    "    detailed.append(d)\n",
    "detailed_df = pd.DataFrame(detailed)\n",
    "print(detailed_df.to_string(index=False))\n",
    "detailed_df.to_csv(\"./output/tabm_simplified/详细性能指标.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = validation_data.copy()\n",
    "val_results[\"真实标签\"] = y_validation_binary.values\n",
    "val_results[\"HPO_预测\"] = metrics_hpo[\"y_pred\"]\n",
    "val_results[\"HPO_概率\"] = metrics_hpo[\"y_proba\"]\n",
    "val_results.to_csv(\"./output/tabm_simplified/验证集预测结果.csv\", index=False)\n",
    "print(f\"验证集预测结果已保存，共 {len(val_results)} 条记录\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TabM精简特征模型训练完成\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"使用特征数: {len(feature_cols_processed)} (vs 全特征38个)\")\n",
    "print(f\"\\n最佳模型: {results.loc[results['AUC'].idxmax(), '模型']}\")\n",
    "print(f\"  AUC: {results['AUC'].max():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}